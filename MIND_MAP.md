> **For AI Agents:** This mind map is your primary knowledge index. Read overview nodes [1-5] first, then follow links [N] to find what you need. Always reference node IDs. When you encounter bugs, document your attempts in relevant nodes. When you make changes, update outdated nodes immediately—especially overview nodes since they're your springboard. Add new nodes only for genuinely new concepts. Keep it compact (20-50 nodes typical). The mind map wraps every task: consult it, rely on it, update it.

[1] **Archlib Overview** - A reusable Python library (`archlib.py`) that implements the Executable Architecture methodology, enabling projects to define their architecture as executable Python code rather than static documentation. The library provides the "Constitution" (metamodel classes) and "Compiler" (validation engine) that projects import to create their own `architecture.py` manifestos. Archlib enforces the Triad of Reality [2] through three node types: Goals (business objectives with acceptance tests), Solutions (architectural strategies with constraints), and Implementations (physical code artifacts with symbol declarations). The library validates traceability (every Implementation → Solution → Goal), dependencies (Solution.requires chains), code inventory (AST parsing confirms declared symbols exist), and test coverage (test files must exist). Projects using archlib replace rotting documentation with living architecture specifications that fail compilation when code drifts from declared structure, preventing architectural debt before it starts. The library supports multi-language AST parsing [7], flexible constraint systems [8], and CLI tooling [9] for validation, mission briefing generation, and targeted test execution.

[2] **Triad of Reality** - The three-layer architectural model that collapses traditional 5-layer waterfall (Intent → Requirement → Design → Task → Test) into recursive Goal → Solution → Implementation hierarchy. Layer 1 (Goal) merges Intent and Requirements, defining "The Why & What" with business objectives and acceptance test paths. Layer 2 (Solution) merges Design, defining "The How" with architectural strategies, dependency declarations, and flexible constraints [8]. Layer 3 (Implementation) replaces Task, defining "The Reality" with physical code files, test files, and symbol declarations (classes, functions, globals) that must exist. Each layer is self-verifying: Goals require acceptance test files, Solutions declare constraints that can reference benchmark scripts, Implementations declare symbols validated via AST parsing [7]. The Triad eliminates the artificial separation between "what" and "how" by recognizing that business goals and technical constraints are inseparable in real systems. This simplification reduces cognitive overhead while maintaining full traceability from code to business value. Projects define their Triad in `architecture.py` [3] which imports archlib classes and instantiates nodes, then runs validation via CLI [9] to ensure architectural integrity.

[3] **Project Manifesto Pattern** - Each project using archlib creates an `architecture.py` file that imports the library (`from archlib import Architecture, Goal, Solution, Implementation`) and defines its specific Triad [2]. The manifesto follows three phases: (1) Define Goals with id_tag, name, and acceptance_test path, (2) Define Solutions that satisfy Goals, declare dependencies via requires, and specify constraints as flexible dictionaries, (3) Define Implementations that implement Solutions, declare code_files and test_files lists, and specify must_define dictionary mapping file paths to required symbol lists. The manifesto instantiates an Architecture object with all nodes and calls `arch.cli()` to enable command-line operations [9]. This pattern separates reusable library code (archlib.py) from project-specific declarations (architecture.py), enabling code reuse while maintaining project autonomy. The manifesto acts as both documentation and validator - reading it explains the architecture, running it validates the architecture. Projects can migrate from v1 methodology [10] by rewriting their architecture.py from scratch using archlib, mapping their existing Intent/Requirement/Design/Task hierarchy to the simplified Triad structure.

[4] **Validation Engine** - The core compiler logic in archlib that performs bidirectional reconciliation between declared architecture and actual codebase state. Validation runs four checks: (1) Traceability validation ensures every Implementation traces through Solution → Goal, every Goal has at least one Solution satisfying it, every Solution has at least one Implementation, preventing orphaned work and unimplemented requirements, (2) Dependency validation checks that all Solution.requires references point to existing Solutions, detects circular dependencies, and validates dependency chains, (3) Code inventory validation uses AST parsing [7] to confirm that every declared symbol (class, function, global) exists in the specified file, and that no undeclared Python/JavaScript files exist without corresponding Implementations, (4) Test inventory validation confirms that all declared test files exist and contain the expected test functions. The validator outputs structured error messages identifying specific violations (missing files, missing symbols, broken dependencies, orphaned goals) and exits with non-zero status on failure, enabling CI/CD integration. The validation engine is extensible - new checks can be added for resource constraint validation, conflict detection, or custom project rules.

[5] **Multi-Language AST Parsing** - The symbol extraction system that validates declared classes, functions, and globals exist in code files. Python parsing uses built-in `ast` module to walk the syntax tree, extracting ClassDef nodes for classes, FunctionDef/AsyncFunctionDef for functions, and top-level Assign/AnnAssign nodes for globals. JavaScript/TypeScript parsing uses tree-sitter [7] with language grammars (tree-sitter-javascript, tree-sitter-typescript) to build proper ASTs and extract ES6 class definitions, function declarations (function, arrow functions, async functions), and module-level exports. The parser handles edge cases: nested classes, decorators, type annotations, module patterns (CommonJS exports, ES6 exports, return object patterns). When tree-sitter is unavailable, the system falls back to regex-based extraction [7] for graceful degradation. The AST parser is language-agnostic - adding support for new languages requires implementing a parse function that extracts symbols from that language's AST. The parser validates symbol existence bidirectionally: top-down (declared symbols must exist) and bottom-up (existing files must be declared), preventing both missing implementations and undocumented code.

[6] **Flexible Constraint System** - Solutions declare constraints as `Dict[str, Any]` dictionaries rather than fixed dataclass structures, enabling project-specific constraint definitions. Constraints can be simple key-value pairs ("complexity": "O(n)", "startup_time": "<50ms") or reference external artifacts ("benchmark": "tests/bench/scoring_bench.py") that turn performance requirements into testable scripts. This flexibility allows projects to define domain-specific constraints (API rate limits, database connection pools, cache eviction policies) without modifying archlib core. The constraint system is extensible - projects can add validation logic that checks constraint values against measured performance, enabling resource budget reconciliation. While v1 used structured ResourceConstraints dataclass with typed fields (cpu_cores, memory_mb, latency_p99_ms), v2's flexible dict approach trades type safety for adaptability, recognizing that constraint categories vary dramatically across projects. Projects can still use structured constraints internally by defining their own dataclasses and storing them as constraint values, maintaining type safety where needed while leveraging archlib's flexibility.

[7] **Tree-Sitter Integration** - JavaScript/TypeScript AST parsing using tree-sitter parser generator with Python bindings. Tree-sitter provides language-agnostic parsing infrastructure with grammar support for 40+ languages, enabling proper AST construction for modern JavaScript (ES6+, JSX, TypeScript) without regex fragility. The integration uses `tree-sitter` Python package with language grammars (`tree-sitter-javascript`, `tree-sitter-typescript`) installed via pip. Parser initialization loads the appropriate language grammar, parses file content into syntax tree, then walks nodes to extract class definitions, function declarations, and module exports. Tree-sitter handles edge cases that regex cannot: nested structures, template literals, decorators, type annotations, async/await syntax. When tree-sitter is unavailable (ImportError), the system falls back to regex-based extraction using patterns for ES6 classes, function declarations, arrow functions, and module exports. This graceful degradation ensures archlib works in environments without tree-sitter while preferring proper AST parsing when available. The fallback regex patterns are based on patterns from chrome_web_speech/architecture.py which successfully extracted symbols from JavaScript files, though less robust than AST parsing for complex syntax.

[8] **CLI Tooling** - Command-line interface enabling `architecture.py` to function as project control plane. The CLI provides three commands: (1) `python architecture.py validate` runs full architectural validation [4], checking traceability, dependencies, code inventory, and test coverage, exiting with error status on failure, (2) `python architecture.py spec --id I-1` generates mission briefing markdown for a specific Implementation, extracting only relevant Goals, Constraints, and file targets to provide focused context for AI agents implementing that task, (3) `python architecture.py test --id I-1` runs tests associated with a node (Implementation test_files or Goal acceptance_test), dispatching to pytest by default but configurable. The CLI uses argparse with subparsers for command routing, enabling extensible command addition. The spec command enables "context slicing" - instead of loading entire codebase context, agents receive minimal focused briefing containing only constraints and requirements relevant to their specific task, dramatically reducing token usage and cognitive load. The test command enables targeted verification, running only tests for the node being worked on rather than full test suite, accelerating development feedback loops. Future CLI enhancements could include graph visualization, dependency analysis, migration helpers, and constraint validation against benchmarks.

[9] **Code Inventory Validation** - Bidirectional validation ensuring declared code matches filesystem reality. Top-down validation checks that every Implementation's declared code_files exist, and that every symbol in must_define dictionary exists in the corresponding file via AST parsing [5]. Bottom-up validation scans the codebase for Python/JavaScript files and ensures each has a corresponding Implementation declaration, preventing undocumented code from accumulating. The validator handles multiple file types: Python files use built-in ast module, JavaScript/TypeScript files use tree-sitter [7] with regex fallback, other file types skip symbol validation but still check file existence. Symbol extraction for Python identifies classes, functions (including async), and top-level globals (distinguishing module-level assignments from function-local assignments). Symbol extraction for JavaScript identifies ES6 classes, function declarations, arrow functions, async functions, and module exports (CommonJS and ES6 patterns). The validator reports specific missing symbols with file paths and line context when available, enabling rapid debugging of declaration mismatches. This bidirectional check prevents both "declared but not implemented" and "implemented but not declared" scenarios, maintaining complete architectural ledger.

[10] **V1 to V2 Migration** - The transition from 5-layer v1 methodology (Intent → Requirement → Design → Task → Test) to 3-layer v2 Triad [2]. Migration involves conceptual mapping: Intent + Requirement → Goal (merge business goals and constraints), Design → Solution (preserve architectural strategy), Task → Implementation (preserve code declarations). Projects rewrite their architecture.py from scratch using archlib rather than attempting compatibility layers, ensuring clean adoption of v2 patterns. The migration preserves validation capabilities (traceability, dependencies, code inventory) while simplifying the model and adding CLI tooling [8]. Key differences: v1 had separate Intent (why) and Requirement (what), v2 merges into Goal (why & what), v1 had 4-level test hierarchy (UAT/System/Integration/Unit), v2 simplifies to acceptance_test path per Goal plus test_files per Implementation, v1 used ResourceConstraints dataclass, v2 uses flexible Dict[str, Any] constraints [6]. Migration reference projects (nub, chrome_web_speech) demonstrate v1 patterns but are not migrated yet - they serve as examples of real-world architecture complexity that v2 must handle. The migration is one-way - v1 projects are rewritten, not gradually converted, ensuring architectural coherence.

[11] **Test Inventory Validation** - Validation ensuring test files exist and contain declared test functions. Goals declare acceptance_test paths that must exist as files. Implementations declare test_files lists that must exist. The validator checks file existence first, then parses test files to extract test function names. Python test files use ast module to find functions starting with "test_" prefix (pytest convention) or matching declared test function names. JavaScript test files use regex to find test/it function calls with string literals as test names. The validator reports missing test files and missing test functions within existing files, enabling test coverage enforcement at architecture level. This validation ensures that architectural declarations about test coverage are backed by actual test files, preventing "tests declared but not written" scenarios. The test inventory check complements code inventory [9] by validating the verification layer matches architectural claims. Future enhancements could validate test quality (coverage metrics, test execution success) but current focus is on existence and symbol presence.

[12] **Dependency Graph Validation** - Validation ensuring Solution dependency chains are valid and acyclic. The validator checks that every Solution.requires reference points to an existing Solution instance, preventing broken dependency declarations. Circular dependency detection walks the dependency graph starting from each Solution, tracking visited nodes to detect cycles that would create impossible dependency chains. The validator reports specific cycles with node IDs, enabling architectural refactoring to break circular dependencies. Dependency validation ensures that architectural decisions about component relationships are logically consistent - if Solution A requires Solution B, then B must exist and cannot require A (directly or transitively). This validation prevents architectural contradictions that would make implementation impossible. The dependency graph can be visualized (future CLI enhancement) to show component relationships and identify architectural bottlenecks or tightly-coupled clusters.

[13] **Traceability Validation** - Validation ensuring every Implementation traces through Solution → Goal chain, proving code serves business value. The validator walks from each Implementation through its implements Solution, then through that Solution's satisfies Goals list, ensuring complete traceability chain exists. It also validates reverse direction: every Goal must have at least one Solution satisfying it (no orphaned goals), every Solution must have at least one Implementation (no unimplemented solutions). This bidirectional traceability prevents architectural drift where code exists without business justification or requirements exist without implementation. The validator reports specific broken chains with node IDs, enabling architectural refactoring to restore traceability. Traceability validation is the core architectural integrity check - if code cannot trace to a business goal, it represents scope creep or technical debt. This enforcement makes architectural decisions explicit and auditable, supporting both development (preventing feature creep) and maintenance (identifying obsolete code).

[14] **Mission Briefing Generation** - The `spec --id` command that generates focused context for AI agents implementing specific tasks. Given an Implementation ID, the command extracts: (1) The Implementation's name and code_files list, (2) The Solution it implements, including Solution name and constraints dictionary, (3) All Goals satisfied by that Solution, including Goal names and acceptance_test paths, (4) The must_define dictionary showing required symbols per file. The output is markdown-formatted mission briefing containing only information relevant to that Implementation, excluding unrelated Goals, Solutions, and Implementations. This "context slicing" dramatically reduces token usage when providing architectural context to AI agents - instead of loading entire architecture.py (potentially thousands of lines), agents receive 50-200 line focused briefing. The briefing format is structured for agent consumption with clear sections (Goals, Constraints, Required Output) and actionable file paths. This enables efficient multi-agent coordination where different agents work on different Implementations with minimal context overlap. The briefing generation is extensible - projects could customize output format or add project-specific sections.

[15] **Library Architecture** - The internal structure of archlib.py separating concerns. The library exports four node classes (Node base class, Goal, Solution, Implementation) that projects subclass or instantiate. The Architecture class encapsulates validation logic [4] and CLI routing [8], taking node lists as constructor parameters. Validation functions are internal (validate_traceability, validate_dependencies, validate_code_inventory, validate_test_inventory) but could be exposed for programmatic access. AST parsing logic [5] is encapsulated in language-specific functions (validate_python_file, validate_javascript_file) with tree-sitter integration [7] handled transparently. The library is designed for single-file distribution (archlib.py) but could be packaged as installable Python package for pip installation. The architecture supports extension points: custom validators, additional CLI commands, new language parsers, constraint validation hooks. The library maintains backward compatibility by adding features rather than breaking changes, enabling projects to adopt new capabilities incrementally. The single-file design keeps archlib lightweight and easy to distribute, while the class-based design enables inheritance and customization for project-specific needs.

[16] **Error Reporting** - Structured error messages that identify specific architectural violations with actionable context. Validation errors include: node ID, error type (missing file, missing symbol, broken dependency, orphaned goal), file path or symbol name, and context about what was expected vs what was found. Error messages are formatted for human readability with emoji indicators (❌ for errors, ⚠️ for warnings) and clear descriptions. The validator collects all errors before reporting, enabling comprehensive violation listing rather than stopping at first error. Error output is designed for both human debugging (clear messages) and CI/CD integration (structured format, exit codes). The validator distinguishes between errors (architectural violations that must be fixed) and warnings (potential issues that don't block validation, like missing test functions or constraint violations). This distinction enables projects to enforce strict architectural rules while allowing gradual migration or optional features. Future enhancements could include error suppression (ignore specific checks), error formatting (JSON output for tooling), and fix suggestions (automated corrections for common violations).

[17] **Extensibility Points** - Mechanisms for projects to extend archlib without modifying core library. Custom validators can be added to Architecture class by subclassing and overriding validate() method, adding project-specific checks (coding standards, naming conventions, documentation requirements). Custom CLI commands can be added via argparse subparsers, enabling project-specific tooling (deployment validation, documentation generation, migration helpers). Custom language parsers can be registered for new file types by implementing symbol extraction functions and adding them to the validation pipeline. Constraint validation hooks enable projects to add logic that checks constraint values against measured performance or external benchmarks. The library's class-based design enables inheritance for customization while maintaining core functionality. Projects can wrap archlib with project-specific abstractions (domain-specific node types, custom validation rules) without forking the library. This extensibility ensures archlib remains lightweight core while supporting diverse project needs through composition rather than configuration bloat.

[18] **Future Enhancements** - Potential additions to archlib beyond core MVP. Graph visualization CLI command (`python architecture.py graph`) generates dependency graph diagrams showing Solution relationships and Implementation mappings. Constraint validation against benchmarks enables automatic checking that measured performance meets declared constraints. Migration helpers assist projects transitioning from v1 to v2 by analyzing existing architecture.py and suggesting Triad mappings. Test execution integration runs declared tests and reports coverage metrics, validating that test_files actually provide adequate coverage. Resource constraint reconciliation compares estimated vs measured constraints, flagging violations when implementations exceed budgets. Conflict detection identifies Solutions with conflicts_with declarations and validates they aren't both instantiated. Documentation generation creates architecture diagrams, dependency graphs, and traceability matrices from node declarations. These enhancements expand archlib from validation tool to full architectural management platform while maintaining core simplicity. Prioritization based on user feedback and real-world usage patterns from migrated projects.

[19] **Design Principles** - Core principles guiding archlib development. Simplicity over completeness - the library does one thing well (architectural validation) rather than attempting to solve all project management problems. Executable over documentation - architecture.py is runnable code that validates itself, not static text that rots. Flexible over rigid - constraints are dictionaries, not fixed schemas, enabling project-specific needs. Fail fast over silent drift - validation errors block progress, preventing architectural debt accumulation. Bidirectional over one-way - code inventory checks both declared→actual and actual→declared, preventing both missing implementations and undocumented code. Extensible over monolithic - library provides hooks for customization rather than attempting to anticipate all needs. These principles ensure archlib remains focused, maintainable, and adaptable to diverse project requirements while providing strong architectural enforcement.

[20] **Implementation Status** - Current development phase and next steps. Archlib is in design phase - the library structure is defined in v2 spec [EXECUTABLE_ARCHITECTURE.v2.md] but not yet implemented. Next steps: (1) Implement archlib.py with core node classes (Goal, Solution, Implementation, Architecture), (2) Implement validation engine [4] with traceability, dependency, code inventory, and test inventory checks, (3) Integrate tree-sitter [7] for JavaScript/TypeScript parsing with regex fallback, (4) Implement CLI tooling [8] with validate, spec, and test commands, (5) Create example architecture.py template demonstrating v2 Triad pattern, (6) Write archlib README.md with usage guide and migration instructions. Once archlib.py is complete, projects (nub, chrome_web_speech) can be migrated from v1 to v2 by rewriting their architecture.py files using archlib. The implementation follows iterative development - core validation first, then CLI, then enhancements based on real-world usage.
